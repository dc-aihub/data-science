{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/dc-aihub/dc-aihub.github.io/blob/master/img/ai-logo-transparent-banner.png?raw=true\" \n",
    "alt=\"Ai/Hub Logo\"/>\n",
    "\n",
    "<h1 style=\"text-align:center;color:#0B8261;\"><center>Data Science</center></h1>\n",
    "<h1 style=\"text-align:center;\"><center>Lesson 14</center></h1>\n",
    "<h1 style=\"text-align:center;\"><center>SVM for Classification</center></h1>\n",
    "\n",
    "<hr />\n",
    "\n",
    "<center><a href=\"#Familiarize\">Familiarize Yourself with the Data</a></center>\n",
    "\n",
    "<center><a href=\"#Dictionary\">Create a Dictionary of Common Words</a></center>\n",
    "\n",
    "<center><a href=\"#Start-SVM\">Time to Start using SVM</a></center>\n",
    "\n",
    "<center><a href=\"#Model-Tuning\">Model Tuning</a></center>\n",
    "\n",
    "<center><a href=\"#Save-Restore\">Save and Restore the Model</a></center>\n",
    "\n",
    "<hr />\n",
    "\n",
    "<center>***Original Tutorial by Savan Patel:*** <br/>https://medium.com/machine-learning-101/chapter-2-svm-support-vector-machine-theory-f0812effc72</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#0B8261; width:100%; height:38px; color:white; font-size:18px; padding:10px;\">\n",
    "OVERVIEW\n",
    "</div>\n",
    "\n",
    "<center style=\"color:#0B8261;\">\n",
    "A Support Vector Machine (SVM) is a Machine Learning algorithm which uses calculus for binary classification. SVMs perform very well when high dimensionality is present (i.e., a lot of features to describe our data). \n",
    "<br/><br/>\n",
    "One unfortunate downfall of SVMs is that they only support binary classification and not multi-class classification. However, there have been recent implementations of SVM that have the added functionality of multi-class classification. \n",
    "<br/><br/>\n",
    "SVMs can get very computationally expensive. If you'd like to learn more about SVMs, please visit <a href=\"https://medium.com/machine-learning-101/chapter-2-svm-support-vector-machine-theory-f0812effc72\">here</a> for a thorough breakdown.\n",
    "</center>\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "<img src=\"https://qph.ec.quoracdn.net/main-qimg-56a04b0f1969a8bee7264a9162e39d0b\" />\n",
    "\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#0B8261; width:100%; height:38px; color:white; font-size:18px; padding:10px;\" id=\"Familiarize\">\n",
    "FAMILIARIZE YOURSELF WITH THE DATA\n",
    "</div>\n",
    "\n",
    "For this tutorial, we will be using the email data found in the data folder within the root of these lessons. Take a quick second to jump into the train and test folders to see what some of these files look like. Familiarization with the data is very important.\n",
    "\n",
    "<div style=\"background:#eee; padding: 15px; margin: 20px\">\n",
    "<pre name=\"3975\" id=\"3975\" class=\"graf graf--pre graf-after--p\" style=\"background:#eee;\"><strong class=\"markup--strong markup--pre-strong\">number-numbermsg[number].txt</strong> : example <strong class=\"markup--strong markup--pre-strong\">3-1msg1.txt</strong> (this are non spam emails)</pre>\n",
    "\n",
    "<pre name=\"f76e\" id=\"f76e\" class=\"graf graf--pre graf-after--pre\" style=\"background:#eee;\">OR</pre>\n",
    "\n",
    "<pre name=\"f8ac\" id=\"f8ac\" class=\"graf graf--pre graf-after--pre\" style=\"background:#eee;\"><strong>spmsg[Number].txt :</strong> example <strong class=\"markup--strong markup--pre-strong\">spmsga162.txt (</strong>these files are of spam emails).</pre>\n",
    "</div>\n",
    "\n",
    "You've probably guessed by now. We are going to be classifying between spam emails and non-spam emails!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The very first step in text data mining task is to clean and prepare the data for a model. In cleaning we remove the non required words, expressions and symbols from text.\n",
    "\n",
    "Consider the text:\n",
    "\n",
    "*\"Hi, this is Alice. Hope you are doing well and enjoying your vacation.\"*\n",
    "\n",
    "Here the words like \"is\", \"this\", \"are\", and \"etc\" don't really contribute to the analysis. Such words are also called stop words.Hence in this exercise, we consider only most frequent 3000 words of dictionary from email. Following is code snippet.\n",
    "\n",
    "After cleaning what we need in every email document, we should be some matrix representation of the word frequency.\n",
    "\n",
    "For example if document contains the text: *\"Hi, this is Alice. Happy Birthday Alice\"* after cleaning, we want something like the following:\n",
    "\n",
    "<div style=\"background:#eee; padding: 15px; margin: 20px\">\n",
    "<pre name=\"6633\" id=\"6633\" class=\"graf graf--pre graf-after--p\" style=\"background:#eee;\">word      :   Hi this is Alice Happy Birthday<br>frequency :   1   1    1  2      1      1</pre>\n",
    "</div>\n",
    "\n",
    "Next, we delete words of length 1 and that are not purely alphabetical.\n",
    "\n",
    "<br/>\n",
    "\n",
    "<div style=\"background-color:#0B8261; width:100%; height:38px; color:white; font-size:18px; padding:10px;\" id=\"Dictionary\">\n",
    "CREATE A DICTIONARY OF COMMON WORDS\n",
    "</div>\n",
    "\n",
    "We then have to create a dictionary of the most common words. This dictionary will be used for our model to identify words going forward. The above matrix kind of resembles a database, but what happens when you have the entire English language? Every sentence will be represented by a database with over 170,000 columns. This will get HUGEEEE!! To avoid this problem, we'll take only the most frequent 3,000 words within all our emails. TWe are going to scan the matrices we create to accomplish this.\n",
    "\n",
    "\n",
    "The following code has been put together to perform this operation. \n",
    "\n",
    "\n",
    "<pre>make_Dictionary reads the email files from a folder, constructs a 3,000 word dictionary for all words.</pre>\n",
    "\n",
    "<pre>extract_features will create the frequency matrix for us.</pre>\n",
    "\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_Dictionary(root_dir):\n",
    "    \n",
    "    all_words = []\n",
    "    emails = [os.path.join(root_dir,f) for f in os.listdir(root_dir)]\n",
    "    \n",
    "    for mail in emails:\n",
    "        with open(mail) as m:\n",
    "            for line in m:\n",
    "                words = line.split()\n",
    "                all_words += words\n",
    "                \n",
    "    dictionary = Counter(all_words)\n",
    "    # if you have python version 3.x use commented version.\n",
    "    list_to_remove = list(dictionary)\n",
    "    \n",
    "    for item in list_to_remove:\n",
    "            # remove if numerical. \n",
    "            if item.isalpha() == False:\n",
    "                        del dictionary[item]\n",
    "            elif len(item) == 1:\n",
    "                del dictionary[item]\n",
    "        # consider only most 3000 common words in dictionary.\n",
    "    dictionary = dictionary.most_common(3000)\n",
    "    return dictionary\n",
    "\n",
    "def extract_features(mail_dir):\n",
    "    files = [os.path.join(mail_dir,fi) for fi in os.listdir(mail_dir)]\n",
    "    features_matrix = np.zeros((len(files),3000))\n",
    "    train_labels = np.zeros(len(files))\n",
    "    count = 0;\n",
    "    step = 0\n",
    "    docID = 0;\n",
    "    for fil in files:\n",
    "        with open(fil) as fi:\n",
    "            for i,line in enumerate(fi):\n",
    "                if i == 2:\n",
    "                    words = line.split()\n",
    "                    for word in words:\n",
    "                        wordID = 0\n",
    "                        for i,d in enumerate(dictionary):\n",
    "                            if d[0] == word:\n",
    "                                wordID = i\n",
    "                                features_matrix[docID,wordID] = words.count(word)\n",
    "            train_labels[docID] = 0;\n",
    "            \n",
    "            # For Windows\n",
    "            filepathTokens = fil.split('\\\\')\n",
    "            \n",
    "            # For Unix based systems\n",
    "            # filepathTokens = fil.split('/')\n",
    "\n",
    "            lastToken = filepathTokens[len(filepathTokens) - 1]\n",
    "            if lastToken.startswith(\"spmsg\"):\n",
    "                train_labels[docID] = 1;\n",
    "                count = count + 1\n",
    "            docID = docID + 1\n",
    "        step = step + 1\n",
    "        \n",
    "        # every 100 files, print a status update for the user.\n",
    "        if step % 100 = 0:\n",
    "            print(\"finished: {}/{} files\".format(counter, len(files)))\n",
    "            \n",
    "    return features_matrix, train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "<div style=\"background-color:#0B8261; width:100%; height:38px; color:white; font-size:18px; padding:10px;\" id=\"Start-SVM\">\n",
    "TIME TO START USING SVM\n",
    "</div>\n",
    "\n",
    "We first import the svc from library. Next, we extract training features and labels. Lastly, we ask model to predict the labels for test set. The basic code block snippet looks like below:\n",
    "\n",
    "<blockquote>**Note: ** You will have to run the code below on your machine to generate the dictionary and feature matrix, which gets stored in RAM for this program. A better approach to this, would be to serialize these objects and store them into a file, which you can then load in in at the future, so you won't have to go through this pre-processing everytime. For now, this will work just fine.</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "TRAIN_DIR = os.path.join(\"..\", \"data\", \"mail_data\", \"train\")\n",
    "TEST_DIR = os.path.join(\"..\", \"data\", \"mail_data\", \"test\")\n",
    "\n",
    "dictionary = make_Dictionary(TRAIN_DIR)\n",
    "\n",
    "# print( \"reading and processing emails from file.\")\n",
    "features_matrix, labels = extract_features(TRAIN_DIR)\n",
    "test_feature_matrix, test_labels = extract_features(TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('order', 1414),\n",
       " ('address', 1299),\n",
       " ('report', 1217),\n",
       " ('mail', 1133),\n",
       " ('language', 1099),\n",
       " ('send', 1080),\n",
       " ('email', 1066),\n",
       " ('program', 1009),\n",
       " ('our', 991),\n",
       " ('list', 946),\n",
       " ('one', 921),\n",
       " ('name', 883),\n",
       " ('receive', 826),\n",
       " ('free', 801),\n",
       " ('money', 797),\n",
       " ('work', 756),\n",
       " ('information', 684),\n",
       " ('business', 669),\n",
       " ('please', 657),\n",
       " ('university', 600),\n",
       " ('us', 567),\n",
       " ('day', 559),\n",
       " ('follow', 545),\n",
       " ('internet', 533),\n",
       " ('over', 514),\n",
       " ('call', 488),\n",
       " ('http', 479),\n",
       " ('check', 475),\n",
       " ('each', 466),\n",
       " ('linguistic', 460),\n",
       " ('include', 452),\n",
       " ('com', 450),\n",
       " ('want', 426),\n",
       " ('need', 426),\n",
       " ('number', 424),\n",
       " ('letter', 420),\n",
       " ('many', 412),\n",
       " ('here', 400),\n",
       " ('market', 398),\n",
       " ('start', 390),\n",
       " ('even', 388),\n",
       " ('fax', 384),\n",
       " ('form', 381),\n",
       " ('most', 377),\n",
       " ('first', 374),\n",
       " ('web', 372),\n",
       " ('service', 365),\n",
       " ('interest', 364),\n",
       " ('software', 362),\n",
       " ('read', 352),\n",
       " ('remove', 349),\n",
       " ('those', 346),\n",
       " ('week', 346),\n",
       " ('credit', 334),\n",
       " ('every', 333),\n",
       " ('site', 331),\n",
       " ('ll', 326),\n",
       " ('english', 325),\n",
       " ('edu', 319),\n",
       " ('much', 318),\n",
       " ('product', 318),\n",
       " ('bulk', 318),\n",
       " ('phone', 315),\n",
       " ('offer', 303),\n",
       " ('best', 302),\n",
       " ('must', 299),\n",
       " ('two', 298),\n",
       " ('cost', 294),\n",
       " ('www', 294),\n",
       " ('computer', 292),\n",
       " ('link', 284),\n",
       " ('state', 279),\n",
       " ('card', 279),\n",
       " ('home', 277),\n",
       " ('own', 275),\n",
       " ('re', 273),\n",
       " ('de', 272),\n",
       " ('available', 270),\n",
       " ('system', 265),\n",
       " ('million', 264),\n",
       " ('message', 262),\n",
       " ('opportunity', 262),\n",
       " ('conference', 261),\n",
       " ('after', 258),\n",
       " ('place', 257),\n",
       " ('question', 257),\n",
       " ('pay', 257),\n",
       " ('within', 255),\n",
       " ('world', 255),\n",
       " ('write', 254),\n",
       " ('hour', 253),\n",
       " ('help', 253),\n",
       " ('sell', 251),\n",
       " ('copy', 248),\n",
       " ('show', 248),\n",
       " ('below', 247),\n",
       " ('same', 243),\n",
       " ('book', 241),\n",
       " ('file', 240),\n",
       " ('through', 235),\n",
       " ('directory', 234),\n",
       " ('before', 232),\n",
       " ('word', 230),\n",
       " ('easy', 230),\n",
       " ('where', 229),\n",
       " ('income', 228),\n",
       " ('try', 227),\n",
       " ('thank', 226),\n",
       " ('tell', 222),\n",
       " ('today', 221),\n",
       " ('company', 220),\n",
       " ('member', 216),\n",
       " ('example', 216),\n",
       " ('back', 214),\n",
       " ('advertise', 214),\n",
       " ('month', 213),\n",
       " ('different', 213),\n",
       " ('subject', 211),\n",
       " ('etc', 209),\n",
       " ('ask', 206),\n",
       " ('contact', 206),\n",
       " ('response', 206),\n",
       " ('cash', 206),\n",
       " ('learn', 205),\n",
       " ('linguist', 205),\n",
       " ('cd', 204),\n",
       " ('little', 203),\n",
       " ('add', 202),\n",
       " ('anyone', 199),\n",
       " ('research', 199),\n",
       " ('per', 199),\n",
       " ('right', 199),\n",
       " ('process', 198),\n",
       " ('down', 197),\n",
       " ('special', 197),\n",
       " ('type', 197),\n",
       " ('again', 197),\n",
       " ('is', 197),\n",
       " ('save', 196),\n",
       " ('least', 195),\n",
       " ('ve', 195),\n",
       " ('live', 195),\n",
       " ('off', 194),\n",
       " ('price', 193),\n",
       " ('level', 192),\n",
       " ('provide', 192),\n",
       " ('line', 191),\n",
       " ('change', 190),\n",
       " ('financial', 189),\n",
       " ('post', 188),\n",
       " ('require', 188),\n",
       " ('search', 187),\n",
       " ('few', 186),\n",
       " ('sure', 186),\n",
       " ('box', 185),\n",
       " ('let', 185),\n",
       " ('paper', 184),\n",
       " ('never', 183),\n",
       " ('ffa', 183),\n",
       " ('life', 181),\n",
       " ('teach', 178),\n",
       " ('text', 177),\n",
       " ('thing', 177),\n",
       " ('page', 177),\n",
       " ('four', 177),\n",
       " ('great', 176),\n",
       " ('case', 175),\n",
       " ('participate', 173),\n",
       " ('really', 172),\n",
       " ('buy', 171),\n",
       " ('between', 170),\n",
       " ('part', 170),\n",
       " ('both', 170),\n",
       " ('net', 170),\n",
       " ('success', 169),\n",
       " ('plan', 169),\n",
       " ('request', 167),\n",
       " ('move', 165),\n",
       " ('simply', 165),\n",
       " ('instruction', 164),\n",
       " ('click', 164),\n",
       " ('reply', 162),\n",
       " ('package', 162),\n",
       " ('discourse', 161),\n",
       " ('method', 161),\n",
       " ('ever', 161),\n",
       " ('less', 160),\n",
       " ('point', 160),\n",
       " ('win', 160),\n",
       " ('seem', 159),\n",
       " ('theory', 158),\n",
       " ('several', 158),\n",
       " ('dollar', 158),\n",
       " ('why', 157),\n",
       " ('step', 157),\n",
       " ('put', 156),\n",
       " ('student', 156),\n",
       " ('important', 156),\n",
       " ('simple', 156),\n",
       " ('rate', 156),\n",
       " ('next', 155),\n",
       " ('thousand', 155),\n",
       " ('friend', 155),\n",
       " ('linguistics', 154),\n",
       " ('ship', 154),\n",
       " ('legal', 153),\n",
       " ('guarantee', 153),\n",
       " ('school', 151),\n",
       " ('course', 151),\n",
       " ('fact', 150),\n",
       " ('return', 150),\n",
       " ('note', 150),\n",
       " ('floodgate', 150),\n",
       " ('position', 149),\n",
       " ('american', 149),\n",
       " ('under', 148),\n",
       " ('account', 147),\n",
       " ('ad', 147),\n",
       " ('keep', 147),\n",
       " ('talk', 147),\n",
       " ('reference', 146),\n",
       " ('since', 146),\n",
       " ('allow', 146),\n",
       " ('analysis', 145),\n",
       " ('better', 145),\n",
       " ('until', 145),\n",
       " ('sale', 145),\n",
       " ('experience', 144),\n",
       " ('result', 144),\n",
       " ('study', 143),\n",
       " ('present', 143),\n",
       " ('speaker', 142),\n",
       " ('grammar', 142),\n",
       " ('remember', 142),\n",
       " ('another', 141),\n",
       " ('city', 140),\n",
       " ('wish', 139),\n",
       " ('problem', 139),\n",
       " ('group', 139),\n",
       " ('believe', 139),\n",
       " ('family', 139),\n",
       " ('person', 139),\n",
       " ('bank', 138),\n",
       " ('international', 136),\n",
       " ('full', 136),\n",
       " ('vium', 136),\n",
       " ('complete', 136),\n",
       " ('print', 136),\n",
       " ('leave', 136),\n",
       " ('once', 136),\n",
       " ('section', 136),\n",
       " ('total', 135),\n",
       " ('lot', 135),\n",
       " ('answer', 135),\n",
       " ('date', 134),\n",
       " ('area', 134),\n",
       " ('too', 134),\n",
       " ('plus', 134),\n",
       " ('georgetown', 134),\n",
       " ('future', 134),\n",
       " ('second', 133),\n",
       " ('department', 133),\n",
       " ('bill', 133),\n",
       " ('office', 132),\n",
       " ('lose', 132),\n",
       " ('issue', 132),\n",
       " ('earn', 132),\n",
       " ('while', 131),\n",
       " ('above', 130),\n",
       " ('long', 130),\n",
       " ('further', 129),\n",
       " ('adult', 129),\n",
       " ('mean', 127),\n",
       " ('join', 127),\n",
       " ('amount', 127),\n",
       " ('ca', 126),\n",
       " ('set', 126),\n",
       " ('video', 126),\n",
       " ('purchase', 126),\n",
       " ('publish', 125),\n",
       " ('without', 125),\n",
       " ('run', 125),\n",
       " ('possible', 124),\n",
       " ('become', 124),\n",
       " ('server', 124),\n",
       " ('real', 123),\n",
       " ('nothing', 123),\n",
       " ('uk', 122),\n",
       " ('job', 122),\n",
       " ('base', 122),\n",
       " ('still', 121),\n",
       " ('something', 120),\n",
       " ('accept', 120),\n",
       " ('already', 120),\n",
       " ('major', 119),\n",
       " ('sign', 119),\n",
       " ('code', 119),\n",
       " ('personal', 119),\n",
       " ('support', 118),\n",
       " ('registration', 118),\n",
       " ('everyone', 118),\n",
       " ('game', 118),\n",
       " ('understand', 116),\n",
       " ('fee', 116),\n",
       " ('small', 115),\n",
       " ('visit', 115),\n",
       " ('however', 115),\n",
       " ('record', 115),\n",
       " ('someone', 115),\n",
       " ('speech', 115),\n",
       " ('minute', 113),\n",
       " ('detail', 113),\n",
       " ('bonus', 112),\n",
       " ('mailing', 112),\n",
       " ('discussion', 111),\n",
       " ('human', 111),\n",
       " ('able', 110),\n",
       " ('hear', 110),\n",
       " ('decide', 110),\n",
       " ('limit', 110),\n",
       " ('john', 109),\n",
       " ('hard', 109),\n",
       " ('secret', 109),\n",
       " ('child', 108),\n",
       " ('rule', 107),\n",
       " ('guide', 107),\n",
       " ('online', 106),\n",
       " ('alway', 106),\n",
       " ('papers', 105),\n",
       " ('begin', 105),\n",
       " ('are', 105),\n",
       " ('sex', 105),\n",
       " ('tax', 105),\n",
       " ('aol', 105),\n",
       " ('exactly', 104),\n",
       " ('open', 103),\n",
       " ('additional', 103),\n",
       " ('reason', 103),\n",
       " ('past', 103),\n",
       " ('virtual', 103),\n",
       " ('profit', 103),\n",
       " ('either', 102),\n",
       " ('investment', 102),\n",
       " ('payment', 101),\n",
       " ('general', 101),\n",
       " ('speak', 101),\n",
       " ('charge', 101),\n",
       " ('actually', 101),\n",
       " ('three', 100),\n",
       " ('application', 100),\n",
       " ('verb', 100),\n",
       " ('content', 100),\n",
       " ('technology', 100),\n",
       " ('sound', 100),\n",
       " ('ye', 100),\n",
       " ('customer', 100),\n",
       " ('teacher', 99),\n",
       " ('break', 99),\n",
       " ('access', 99),\n",
       " ('pass', 98),\n",
       " ('anywhere', 98),\n",
       " ('fill', 97),\n",
       " ('acquisition', 97),\n",
       " ('happen', 97),\n",
       " ('immediately', 97),\n",
       " ('usa', 96),\n",
       " ('build', 96),\n",
       " ('though', 96),\n",
       " ('electronic', 96),\n",
       " ('structure', 96),\n",
       " ('washington', 96),\n",
       " ('choose', 96),\n",
       " ('ed', 95),\n",
       " ('knowledge', 95),\n",
       " ('communication', 94),\n",
       " ('abstract', 94),\n",
       " ('assume', 94),\n",
       " ('html', 94),\n",
       " ('true', 94),\n",
       " ('anything', 93),\n",
       " ('meet', 93),\n",
       " ('ac', 93),\n",
       " ('direct', 93),\n",
       " ('material', 93),\n",
       " ('feel', 93),\n",
       " ('wait', 92),\n",
       " ('yourself', 92),\n",
       " ('consider', 91),\n",
       " ('topic', 91),\n",
       " ('syntax', 90),\n",
       " ('contain', 90),\n",
       " ('hand', 90),\n",
       " ('science', 90),\n",
       " ('old', 89),\n",
       " ('datum', 89),\n",
       " ('manual', 89),\n",
       " ('generate', 89),\n",
       " ('end', 89),\n",
       " ('soon', 89),\n",
       " ('single', 88),\n",
       " ('title', 88),\n",
       " ('standard', 88),\n",
       " ('professional', 88),\n",
       " ('create', 88),\n",
       " ('ago', 87),\n",
       " ('later', 87),\n",
       " ('claim', 87),\n",
       " ('bring', 87),\n",
       " ('national', 87),\n",
       " ('continue', 87),\n",
       " ('away', 87),\n",
       " ('postal', 87),\n",
       " ('envelope', 87),\n",
       " ('top', 86),\n",
       " ('participant', 85),\n",
       " ('german', 85),\n",
       " ('kind', 85),\n",
       " ('feature', 85),\n",
       " ('everything', 85),\n",
       " ('phonology', 84),\n",
       " ('hundred', 84),\n",
       " ('delete', 84),\n",
       " ('history', 83),\n",
       " ('matter', 83),\n",
       " ('else', 83),\n",
       " ('stop', 83),\n",
       " ('development', 82),\n",
       " ('center', 82),\n",
       " ('links', 82),\n",
       " ('natural', 81),\n",
       " ('apply', 81),\n",
       " ('march', 81),\n",
       " ('window', 81),\n",
       " ('currency', 81),\n",
       " ('orders', 81),\n",
       " ('source', 80),\n",
       " ('telephone', 80),\n",
       " ('mention', 80),\n",
       " ('involve', 80),\n",
       " ('share', 80),\n",
       " ('express', 80),\n",
       " ('pp', 80),\n",
       " ('stealth', 80),\n",
       " ('session', 79),\n",
       " ('idea', 79),\n",
       " ('version', 79),\n",
       " ('yours', 79),\n",
       " ('debt', 79),\n",
       " ('car', 78),\n",
       " ('large', 78),\n",
       " ('far', 78),\n",
       " ('action', 78),\n",
       " ('test', 78),\n",
       " ('country', 78),\n",
       " ('ready', 78),\n",
       " ('figure', 78),\n",
       " ('target', 78),\n",
       " ('dream', 78),\n",
       " ('relate', 77),\n",
       " ('approach', 77),\n",
       " ('advantage', 77),\n",
       " ('tool', 77),\n",
       " ('russian', 77),\n",
       " ('woman', 77),\n",
       " ('visa', 77),\n",
       " ('watch', 77),\n",
       " ('education', 76),\n",
       " ('view', 76),\n",
       " ('handle', 76),\n",
       " ('construction', 75),\n",
       " ('high', 75),\n",
       " ('man', 75),\n",
       " ('effort', 75),\n",
       " ('press', 75),\n",
       " ('chair', 75),\n",
       " ('chance', 75),\n",
       " ('risk', 75),\n",
       " ('summary', 74),\n",
       " ('spend', 74),\n",
       " ('extra', 74),\n",
       " ('potential', 74),\n",
       " ('value', 73),\n",
       " ('dialect', 73),\n",
       " ('dr', 73),\n",
       " ('easily', 73),\n",
       " ('hold', 73),\n",
       " ('prove', 73),\n",
       " ('zip', 73),\n",
       " ('whole', 73),\n",
       " ('reports', 73),\n",
       " ('capitalfm', 73),\n",
       " ('house', 72),\n",
       " ('review', 72),\n",
       " ('current', 72),\n",
       " ('organization', 72),\n",
       " ('turn', 72),\n",
       " ('music', 72),\n",
       " ('download', 72),\n",
       " ('offshore', 72),\n",
       " ('society', 71),\n",
       " ('class', 71),\n",
       " ('age', 71),\n",
       " ('law', 71),\n",
       " ('mind', 71),\n",
       " ('reach', 71),\n",
       " ('query', 70),\n",
       " ('field', 70),\n",
       " ('original', 70),\n",
       " ('drive', 70),\n",
       " ('collect', 70),\n",
       " ('fun', 70),\n",
       " ('always', 70),\n",
       " ('discover', 69),\n",
       " ('cut', 69),\n",
       " ('street', 69),\n",
       " ('advertisement', 69),\n",
       " ('publication', 68),\n",
       " ('almost', 68),\n",
       " ('term', 68),\n",
       " ('enter', 68),\n",
       " ('against', 68),\n",
       " ('story', 68),\n",
       " ('york', 68),\n",
       " ('dear', 68),\n",
       " ('security', 68),\n",
       " ('millions', 68),\n",
       " ('social', 67),\n",
       " ('around', 67),\n",
       " ('enclose', 67),\n",
       " ('la', 67),\n",
       " ('successful', 67),\n",
       " ('power', 67),\n",
       " ('pronoun', 67),\n",
       " ('effective', 67),\n",
       " ('select', 67),\n",
       " ('format', 67),\n",
       " ('probably', 67),\n",
       " ('engine', 67),\n",
       " ('hope', 66),\n",
       " ('respond', 66),\n",
       " ('st', 66),\n",
       " ('native', 66),\n",
       " ('ny', 66),\n",
       " ('means', 66),\n",
       " ('individual', 66),\n",
       " ('user', 66),\n",
       " ('doubt', 66),\n",
       " ('room', 65),\n",
       " ('various', 65),\n",
       " ('yet', 65),\n",
       " ('vowel', 65),\n",
       " ('rest', 65),\n",
       " ('completely', 65),\n",
       " ('travel', 65),\n",
       " ('directly', 64),\n",
       " ('whether', 64),\n",
       " ('along', 64),\n",
       " ('sentence', 64),\n",
       " ('inc', 64),\n",
       " ('big', 64),\n",
       " ('foreign', 63),\n",
       " ('deal', 63),\n",
       " ('phonetic', 63),\n",
       " ('resource', 63),\n",
       " ('institute', 63),\n",
       " ('vol', 63),\n",
       " ('rather', 63),\n",
       " ('finally', 63),\n",
       " ('comment', 63),\n",
       " ('id', 63),\n",
       " ('increase', 63),\n",
       " ('shor', 63),\n",
       " ('sales', 63),\n",
       " ('quite', 62),\n",
       " ('short', 62),\n",
       " ('register', 62),\n",
       " ('train', 62),\n",
       " ('invite', 62),\n",
       " ('journal', 62),\n",
       " ('announcement', 62),\n",
       " ('raise', 62),\n",
       " ('appear', 62),\n",
       " ('goal', 62),\n",
       " ('together', 62),\n",
       " ('connection', 62),\n",
       " ('mass', 62),\n",
       " ('capital', 62),\n",
       " ('david', 61),\n",
       " ('french', 61),\n",
       " ('object', 61),\n",
       " ('produce', 61),\n",
       " ('enough', 61),\n",
       " ('chinese', 61),\n",
       " ('miss', 61),\n",
       " ('freedom', 61),\n",
       " ('design', 60),\n",
       " ('semantic', 60),\n",
       " ('certain', 60),\n",
       " ('rich', 60),\n",
       " ('japanese', 60),\n",
       " ('payable', 59),\n",
       " ('expect', 59),\n",
       " ('america', 59),\n",
       " ('main', 59),\n",
       " ('website', 59),\n",
       " ('huge', 59),\n",
       " ('circular', 58),\n",
       " ('ability', 58),\n",
       " ('phenomenon', 58),\n",
       " ('info', 58),\n",
       " ('develop', 58),\n",
       " ('quality', 58),\n",
       " ('loan', 58),\n",
       " ('attention', 57),\n",
       " ('control', 57),\n",
       " ('perhap', 57),\n",
       " ('digital', 57),\n",
       " ('computational', 57),\n",
       " ('play', 57),\n",
       " ('explain', 57),\n",
       " ('entire', 57),\n",
       " ('lead', 57),\n",
       " ('mastercard', 57),\n",
       " ('culture', 56),\n",
       " ('historical', 56),\n",
       " ('advance', 56),\n",
       " ('domain', 56),\n",
       " ('low', 56),\n",
       " ('difference', 56),\n",
       " ('academic', 56),\n",
       " ('index', 56),\n",
       " ('multus', 56),\n",
       " ('happy', 56),\n",
       " ('literature', 55),\n",
       " ('article', 55),\n",
       " ('aspect', 55),\n",
       " ('due', 55),\n",
       " ('po', 55),\n",
       " ('specific', 55),\n",
       " ('spanish', 55),\n",
       " ('model', 55),\n",
       " ('local', 55),\n",
       " ('federal', 55),\n",
       " ('dept', 55),\n",
       " ('especially', 55),\n",
       " ('associate', 55),\n",
       " ('don', 55),\n",
       " ('reduplication', 54),\n",
       " ('exchange', 54),\n",
       " ('mary', 54),\n",
       " ('mark', 54),\n",
       " ('author', 54),\n",
       " ('six', 54),\n",
       " ('judgment', 54),\n",
       " ('latest', 54),\n",
       " ('master', 54),\n",
       " ('public', 54),\n",
       " ('sexual', 54),\n",
       " ('tm', 54),\n",
       " ('cover', 53),\n",
       " ('recent', 53),\n",
       " ('correct', 53),\n",
       " ('common', 53),\n",
       " ('suite', 53),\n",
       " ('close', 53),\n",
       " ('error', 53),\n",
       " ('piece', 53),\n",
       " ('recruit', 53),\n",
       " ('fresh', 53),\n",
       " ('filter', 53),\n",
       " ('hot', 53),\n",
       " ('european', 52),\n",
       " ('project', 52),\n",
       " ('track', 52),\n",
       " ('update', 52),\n",
       " ('exist', 52),\n",
       " ('mailer', 52),\n",
       " ('kid', 52),\n",
       " ('seven', 52),\n",
       " ('news', 52),\n",
       " ('fast', 52),\n",
       " ('profitable', 52),\n",
       " ('mlm', 52),\n",
       " ('hotel', 51),\n",
       " ('prepare', 51),\n",
       " ('le', 51),\n",
       " ('volume', 51),\n",
       " ('college', 51),\n",
       " ('often', 51),\n",
       " ('absolutely', 51),\n",
       " ('grammatical', 51),\n",
       " ('june', 51),\n",
       " ('january', 51),\n",
       " ('sometime', 51),\n",
       " ('cognitive', 51),\n",
       " ('concern', 51),\n",
       " ('deliver', 51),\n",
       " ('provider', 51),\n",
       " ('invest', 51),\n",
       " ('deat', 50),\n",
       " ('speed', 50),\n",
       " ('submit', 50),\n",
       " ('formal', 50),\n",
       " ('locate', 50),\n",
       " ('love', 50),\n",
       " ('direction', 50),\n",
       " ('enjoy', 50),\n",
       " ('themselve', 50),\n",
       " ('government', 50),\n",
       " ('discuss', 49),\n",
       " ('pragmatic', 49),\n",
       " ('couple', 49),\n",
       " ('population', 49),\n",
       " ('particle', 49),\n",
       " ('indicate', 49),\n",
       " ('committee', 49),\n",
       " ('half', 49),\n",
       " ('century', 49),\n",
       " ('worldwide', 49),\n",
       " ('qualify', 49),\n",
       " ('database', 49),\n",
       " ('compuserve', 49),\n",
       " ('hit', 49),\n",
       " ('third', 48),\n",
       " ('modern', 48),\n",
       " ('upon', 48),\n",
       " ('grow', 48),\n",
       " ('category', 48),\n",
       " ('situation', 48),\n",
       " ('californium', 48),\n",
       " ('morphology', 48),\n",
       " ('technical', 48),\n",
       " ('refer', 48),\n",
       " ('intelligence', 48),\n",
       " ('imagine', 48),\n",
       " ('club', 48),\n",
       " ('powerful', 48),\n",
       " ('goldrush', 48),\n",
       " ('dori', 48),\n",
       " ('context', 47),\n",
       " ('wide', 47),\n",
       " ('suggest', 47),\n",
       " ('myself', 47),\n",
       " ('clear', 47),\n",
       " ('agree', 47),\n",
       " ('distinction', 47),\n",
       " ('girl', 47),\n",
       " ('hr', 47),\n",
       " ('sort', 47),\n",
       " ('discount', 47),\n",
       " ('htm', 47),\n",
       " ('tel', 46),\n",
       " ('syntactic', 46),\n",
       " ('recently', 46),\n",
       " ('principle', 46),\n",
       " ('early', 46),\n",
       " ('comparison', 46),\n",
       " ('longer', 46),\n",
       " ('submission', 46),\n",
       " ('cannot', 46),\n",
       " ('phrase', 46),\n",
       " ('benefit', 46),\n",
       " ('length', 46),\n",
       " ('pick', 46),\n",
       " ('membership', 46),\n",
       " ('excite', 46),\n",
       " ('isp', 46),\n",
       " ('ems', 46),\n",
       " ('signature', 45),\n",
       " ('wonder', 45),\n",
       " ('unite', 45),\n",
       " ('respondent', 45),\n",
       " ('particular', 45),\n",
       " ('basis', 45),\n",
       " ('non', 45),\n",
       " ('similar', 45),\n",
       " ('toll', 45),\n",
       " ('delivery', 45),\n",
       " ('tense', 45),\n",
       " ('sincerely', 45),\n",
       " ('works', 45),\n",
       " ('boyfriend', 45),\n",
       " ('lunch', 44),\n",
       " ('sample', 44),\n",
       " ('relative', 44),\n",
       " ('forward', 44),\n",
       " ('instead', 44),\n",
       " ('july', 44),\n",
       " ('workshop', 44),\n",
       " ('sheet', 44),\n",
       " ('road', 44),\n",
       " ('space', 44),\n",
       " ('period', 44),\n",
       " ('yes', 44),\n",
       " ('quickly', 44),\n",
       " ('using', 44),\n",
       " ('worth', 44),\n",
       " ('partner', 44),\n",
       " ('movement', 44),\n",
       " ('luck', 44),\n",
       " ('five', 44),\n",
       " ('perfectly', 44),\n",
       " ('chechen', 44),\n",
       " ('forget', 43),\n",
       " ('february', 43),\n",
       " ('propose', 43),\n",
       " ('candidate', 43),\n",
       " ('inquiry', 43),\n",
       " ('lexical', 43),\n",
       " ('outside', 43),\n",
       " ('evidence', 43),\n",
       " ('initial', 43),\n",
       " ('enterprise', 43),\n",
       " ('quick', 43),\n",
       " ('private', 43),\n",
       " ('postage', 43),\n",
       " ('der', 43),\n",
       " ('reduce', 43),\n",
       " ('hello', 43),\n",
       " ('unique', 42),\n",
       " ('practice', 42),\n",
       " ('commercial', 42),\n",
       " ('deaf', 42),\n",
       " ('canada', 42),\n",
       " ('legitimate', 42),\n",
       " ('industry', 42),\n",
       " ('regard', 42),\n",
       " ('beautiful', 42),\n",
       " ('chain', 42),\n",
       " ('campaign', 42),\n",
       " ('cent', 42),\n",
       " ('amaze', 42),\n",
       " ('duplicate', 42),\n",
       " ('celebrity', 42),\n",
       " ('quote', 41),\n",
       " ('effect', 41),\n",
       " ('actual', 41),\n",
       " ('community', 41),\n",
       " ('paul', 41),\n",
       " ('frank', 41),\n",
       " ('shop', 41),\n",
       " ('technique', 41),\n",
       " ('universal', 41),\n",
       " ('picture', 41),\n",
       " ('introduce', 41),\n",
       " ('phonological', 41),\n",
       " ('forum', 41),\n",
       " ('background', 41),\n",
       " ('ipa', 41),\n",
       " ('stock', 41),\n",
       " ('act', 41),\n",
       " ('ok', 41),\n",
       " ('org', 41),\n",
       " ('truly', 41),\n",
       " ('agency', 41),\n",
       " ('rights', 41),\n",
       " ('paradise', 41),\n",
       " ('alter', 41),\n",
       " ('self', 41),\n",
       " ('corporation', 41),\n",
       " ('marketing', 41),\n",
       " ('independent', 40),\n",
       " ('evaluation', 40),\n",
       " ('drop', 40),\n",
       " ('theoretical', 40),\n",
       " ('replace', 40),\n",
       " ('presentation', 40),\n",
       " ('seminar', 40),\n",
       " ('voice', 40),\n",
       " ('description', 40),\n",
       " ('table', 40),\n",
       " ('global', 40),\n",
       " ('document', 40),\n",
       " ('thanks', 40),\n",
       " ('compare', 40),\n",
       " ('collection', 40),\n",
       " ('alone', 40),\n",
       " ('monthly', 40),\n",
       " ('optional', 40),\n",
       " ('september', 39),\n",
       " ('activity', 39),\n",
       " ('night', 39),\n",
       " ('prefer', 39),\n",
       " ('north', 39),\n",
       " ('final', 39),\n",
       " ('organizer', 39),\n",
       " ('au', 39),\n",
       " ('although', 39),\n",
       " ('disk', 39),\n",
       " ('summer', 39),\n",
       " ('richard', 39),\n",
       " ('higher', 39),\n",
       " ('achieve', 39),\n",
       " ('synthetic', 39),\n",
       " ('treat', 39),\n",
       " ('fund', 39),\n",
       " ('block', 39),\n",
       " ('nor', 39),\n",
       " ('artificial', 39),\n",
       " ('url', 39),\n",
       " ('operate', 39),\n",
       " ('expression', 39),\n",
       " ('insurance', 39),\n",
       " ('clean', 39),\n",
       " ('choice', 39),\n",
       " ('automatically', 39),\n",
       " ('retire', 39),\n",
       " ('girlfriend', 39),\n",
       " ('depend', 38),\n",
       " ('degree', 38),\n",
       " ('maybe', 38),\n",
       " ('tape', 38),\n",
       " ('introduction', 38),\n",
       " ('concept', 38),\n",
       " ('beach', 38),\n",
       " ('graphic', 38),\n",
       " ('except', 38),\n",
       " ('pc', 38),\n",
       " ('promise', 38),\n",
       " ('proof', 38),\n",
       " ('release', 38),\n",
       " ('moment', 38),\n",
       " ('forever', 38),\n",
       " ('spam', 38),\n",
       " ('xxx', 38),\n",
       " ('late', 37),\n",
       " ('graduate', 37),\n",
       " ('focus', 37),\n",
       " ('deadline', 37),\n",
       " ('certainly', 37),\n",
       " ('south', 37),\n",
       " ('across', 37),\n",
       " ('conversation', 37),\n",
       " ('argument', 37),\n",
       " ('symbol', 37),\n",
       " ('dc', 37),\n",
       " ('sum', 37),\n",
       " ('hesitate', 37),\n",
       " ('task', 37),\n",
       " ('necessary', 37),\n",
       " ('daily', 37),\n",
       " ('comparative', 37),\n",
       " ('co', 37),\n",
       " ('sake', 37),\n",
       " ('opposite', 37),\n",
       " ('totally', 37),\n",
       " ('benjamin', 37),\n",
       " ('rom', 37),\n",
       " ('addresses', 37),\n",
       " ('color', 37),\n",
       " ('mortgage', 37),\n",
       " ('refund', 37),\n",
       " ('relax', 37),\n",
       " ('michael', 36),\n",
       " ('sense', 36),\n",
       " ('relationship', 36),\n",
       " ('dutch', 36),\n",
       " ('participation', 36),\n",
       " ('highly', 36),\n",
       " ('whatever', 36),\n",
       " ('addition', 36),\n",
       " ('eliminate', 36),\n",
       " ('cc', 36),\n",
       " ('describe', 36),\n",
       " ('guvax', 36),\n",
       " ('interpretation', 36),\n",
       " ('obviously', 36),\n",
       " ('succeed', 36),\n",
       " ('editor', 36),\n",
       " ('clause', 36),\n",
       " ('air', 36),\n",
       " ('header', 36),\n",
       " ('extremely', 36),\n",
       " ('prompt', 36),\n",
       " ('ingush', 36),\n",
       " ('trade', 36),\n",
       " ('competition', 36),\n",
       " ('client', 36),\n",
       " ('resell', 36),\n",
       " ('semantics', 35),\n",
       " ('item', 35),\n",
       " ('cultural', 35),\n",
       " ('transfer', 35),\n",
       " ('obtain', 35),\n",
       " ('translation', 35),\n",
       " ('edinburgh', 35),\n",
       " ('function', 35),\n",
       " ('inform', 35),\n",
       " ('ignore', 35),\n",
       " ('ten', 35),\n",
       " ('among', 35),\n",
       " ('unlimit', 35),\n",
       " ('london', 35),\n",
       " ('element', 35),\n",
       " ('december', 35),\n",
       " ('separate', 35),\n",
       " ('bottom', 35),\n",
       " ('toward', 35),\n",
       " ('germany', 35),\n",
       " ('regular', 35),\n",
       " ...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Let's observe what the dictionary looks like.\n",
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# observe your dictionary\n",
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# observe your features matrix\n",
    "features_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# observe the classification labels\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model.\n",
      "FINISHED classifying. accuracy score : \n",
      "0.815384615385\n"
     ]
    }
   ],
   "source": [
    "model = svm.SVC()\n",
    "\n",
    "print( \"Training model.\")\n",
    "\n",
    "# train the model\n",
    "model.fit(features_matrix, labels)\n",
    "\n",
    "# test the model\n",
    "predicted_labels = model.predict(test_feature_matrix)\n",
    "\n",
    "print( \"FINISHED classifying. accuracy score : \")\n",
    "print( accuracy_score(test_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote name=\"bda8\" id=\"bda8\" class=\"graf graf--blockquote graf-after--pre\">This is very basic implementation. It assumes default values of the following tuning hyperparameters (kernel = linear, C = 1 and gamma = 1)</blockquote>\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "<div style=\"background-color:#D33222; margin-left:10%; width:90%; height:38px; color:white; font-size:18px; padding:10px; float:right;\">\n",
    "NOTE\n",
    "</div>\n",
    ">- I suggest going through the code above and outputting the dictionary within the provided cell to see what it looks like.\n",
    ">- You can even do this for the features_matrix and labels.\n",
    ">- This will give you a good idea as to what the data looks like that is being fed into your Machine Learning algorithm!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#0B8261; width:100%; height:38px; color:white; font-size:18px; padding:10px;\" id=\"Model-Tuning\">\n",
    "MODEL TUNING\n",
    "</div>\n",
    "\n",
    "There are a few things we can do to tune our SVM model, which will be explained below. The explanations behind each of these hyperparameters are included in the link mentioned in the beginning of this lesson. \n",
    "\n",
    "### <span style=\"color: #a1a1a1;\">1. Kernel</span>\n",
    "\n",
    "Change **kernel** to rbf. i.e. in model = SVC() add kernel parameter\n",
    "\n",
    "<pre name=\"9d85\" id=\"9d85\" class=\"graf graf--pre graf-after--p\" style=\"background:#eee;padding: 10px\">model = svm.SVC(kernel=\"rbf\", C = 1)</pre>\n",
    "\n",
    "### <span style=\"color: #a1a1a1;\">2. C</span>\n",
    "\n",
    "Next vary **C (regularization parameter)** as **10, 100, 1000, 10000**. Determine whether accuracy increases or decreases?\n",
    "\n",
    "<blockquote>*You will notice that at C = 100, the accuracy score increases to 85.38% and remains almost same beyond that.*</blockquote>\n",
    "\n",
    "### <span style=\"color: #a1a1a1;\">3. Gamma</span>\n",
    "\n",
    "**At last, lets play with gamma**. Add one more parameter gamma = 1.0\n",
    "\n",
    "<pre name=\"07a7\" id=\"07a7\" class=\"graf graf--pre graf-after--p\" style=\"background:#eee;padding: 10px\">model = svm.SVC(kernel=\"rbf\", C=100, gamma=1)</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model.\n",
      "FINISHED classifying. accuracy score : \n",
      "0.538461538462\n"
     ]
    }
   ],
   "source": [
    "model = svm.SVC(kernel=\"rbf\", C=100, gamma=1)\n",
    "\n",
    "print( \"Training model.\")\n",
    "\n",
    "# train the model\n",
    "model.fit(features_matrix, labels)\n",
    "\n",
    "# test the model\n",
    "predicted_labels = model.predict(test_feature_matrix)\n",
    "\n",
    "print( \"FINISHED classifying. accuracy score : \")\n",
    "print( accuracy_score(test_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What on earth just happened? Our model accuracy dropped! Let's try bringing the gamma value down a bit more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model.\n",
      "FINISHED classifying. accuracy score : \n",
      "0.973076923077\n"
     ]
    }
   ],
   "source": [
    "model = svm.SVC(kernel=\"rbf\", C=100, gamma=0.001)\n",
    "\n",
    "print( \"Training model.\")\n",
    "\n",
    "# train the model\n",
    "model.fit(features_matrix, labels)\n",
    "\n",
    "# test the model\n",
    "predicted_labels = model.predict(test_feature_matrix)\n",
    "\n",
    "print( \"FINISHED classifying. accuracy score : \")\n",
    "print( accuracy_score(test_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazing! Looks like we've achieved a much better score than before. Success!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "<div style=\"background-color:#0B8261; width:100%; height:38px; color:white; font-size:18px; padding:10px;\" id=\"Save-Restore\">\n",
    "SAVING &AMP; RESTORING OUR MODEL (OPTIONAL)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed that every time the script takes lot of time in cleaning and reading data(features and labels) from emails. You can speed up the process by saving the data once extracted from first run.\n",
    "\n",
    "<blockquote>This will save you lot more time focusing on learning tuning parameters.</blockquote>\n",
    "\n",
    "Use following snippet to your code to save and load.\n",
    "\n",
    "**Note: ** you may have to run the following in your command line to install cPickle if the code gives you an error:\n",
    "\n",
    "<pre style=\"padding: 10px; background: #eee\">pip install pickle</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "\n",
    "def load(file_name):\n",
    "    # load the model\n",
    "    stream = gzip.open(file_name, \"rb\")\n",
    "    model = pickle.load(stream)\n",
    "    stream.close()\n",
    "    return model\n",
    "\n",
    "def save(file_name, model):\n",
    "    # save the model\n",
    "    stream = gzip.open(file_name, \"wb\")\n",
    "    pickle.dump(model, stream)\n",
    "    stream.close()\n",
    "    \n",
    "# To save\n",
    "# Unix-based systems\n",
    "save(os.path.join(\".\", \"tmp\", \"features_matrix\"), features_matrix)\n",
    "save(os.path.join(\".\", \"tmp\", \"labels\"), labels)\n",
    "save(os.path.join(\".\", \"tmp\", \"test_features_matrix\"), test_feature_matrix)\n",
    "save(os.path.join(\".\", \"tmp\", \"test_features_matrix\"), test_labels)\n",
    "\n",
    "# #To load\n",
    "features_matrix = load(os.path.join(\".\", \"tmp\", \"features_matrix\"))\n",
    "labels = load(os.path.join(\".\", \"tmp\", \"labels\"))\n",
    "test_feature_matrix = load(os.path.join(\".\", \"tmp\", \"test_features_matrix\"))\n",
    "test_labels = load(os.path.join(\".\", \"tmp\", \"test_features_matrix\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
