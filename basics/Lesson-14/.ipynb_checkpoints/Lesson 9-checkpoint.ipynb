{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is to get all the code from before in this notebook so you can continue without typing everything out again. \n",
    "# requirements.py should have been provided with this lesson.\n",
    "%run requirements.py\n",
    "%matplotlib inline\n",
    "mpl.style.use('ggplot')\n",
    "sns.set_style('white')\n",
    "pylab.rcParams['figure.figsize'] = 12,8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:right;\">This tutorial is taken from: https://www.kaggle.com/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"width:450px;\" src=\"https://durhamcollege.ca/wp-content/uploads/ai-hub-header.jpg\" alt=\"DC Logo\"/>\n",
    "\n",
    "<h1 style=\"text-align:center;\">Data Science 101</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color: #16a085\">LESSON 9</span> - Validate and Implement\n",
    "\n",
    "Now that we've gone ahead and tuned our model to the best of our ability, the next step is to prepare for submission using the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'correlation_heatmap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-ccbe03d8b698>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#compare algorithm predictions with each other, where 1 = exactly similar and 0 = exactly opposite\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#there are some 1's, but enough blues and light reds to create a \"super algorithm\" by combining them\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcorrelation_heatmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMLA_predict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'correlation_heatmap' is not defined"
     ]
    }
   ],
   "source": [
    "#compare algorithm predictions with each other, where 1 = exactly similar and 0 = exactly opposite\n",
    "#there are some 1's, but enough blues and light reds to create a \"super algorithm\" by combining them\n",
    "correlation_heatmap(MLA_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"color: #e74c3c; text-align: center\">STOP</p>\n",
    "\n",
    "<p style=\"color: #e74c3c; text-align: center\">*Take some time to understand the code and the output above (**the scores are important**). You don't have to understand every line of code, but make sure you get what it's trying to accomplish*</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "\n",
    "### <span style=\"color: #16a085\">Tune Model with Feature Selection</span>\n",
    "\n",
    "As stated in the beginning, more predictor variables do not make a better model, but the right predictors do. So another step in data modeling is feature selection. Sklearn has several options, we will use recursive feature elimination (RFE) with cross validation (CV).\n",
    "\n",
    "**Feature Selection** essentially allows us to select the most important features. For example, we wouldn't want a feature such as *hair color* to be represented in this dataset as it has no effect on the outcome of the passenger surviving or not. It could, coincidentally end up swaying the model one way or another if we include it within our feature set, which is not good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE DT RFE Training Shape Old:  (891, 7)\n",
      "BEFORE DT RFE Training Columns Old:  ['Sex_Code' 'Pclass' 'Embarked_Code' 'Title_Code' 'FamilySize'\n",
      " 'AgeBin_Code' 'FareBin_Code']\n",
      "BEFORE DT RFE Training w/bin score mean: 89.51\n",
      "BEFORE DT RFE Test w/bin score mean: 82.09\n",
      "BEFORE DT RFE Test w/bin score 3*std: +/- 5.57\n",
      "----------\n",
      "AFTER DT RFE Training Shape New:  (891, 6)\n",
      "AFTER DT RFE Training Columns New:  ['Sex_Code' 'Pclass' 'Title_Code' 'FamilySize' 'AgeBin_Code' 'FareBin_Code']\n",
      "AFTER DT RFE Training w/bin score mean: 88.16\n",
      "AFTER DT RFE Test w/bin score mean: 83.06\n",
      "AFTER DT RFE Test w/bin score 3*std: +/- 6.22\n",
      "----------\n",
      "AFTER DT RFE Tuned Parameters:  {'criterion': 'gini', 'max_depth': 4, 'random_state': 0}\n",
      "AFTER DT RFE Tuned Training w/bin score mean: 89.39\n",
      "AFTER DT RFE Tuned Test w/bin score mean: 87.34\n",
      "AFTER DT RFE Tuned Test w/bin score 3*std: +/- 6.21\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "#base model\n",
    "print('BEFORE DT RFE Training Shape Old: ', data1[data1_x_bin].shape) \n",
    "print('BEFORE DT RFE Training Columns Old: ', data1[data1_x_bin].columns.values)\n",
    "\n",
    "print(\"BEFORE DT RFE Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \n",
    "print(\"BEFORE DT RFE Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\n",
    "print(\"BEFORE DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(base_results['test_score'].std()*100*3))\n",
    "print('-'*10)\n",
    "\n",
    "\n",
    "\n",
    "#feature selection\n",
    "dtree_rfe = feature_selection.RFECV(dtree, step = 1, scoring = 'accuracy', cv = cv_split)\n",
    "dtree_rfe.fit(data1[data1_x_bin], data1[Target])\n",
    "\n",
    "#transform x&y to reduced features and fit new model\n",
    "#alternative: can use pipeline to reduce fit and transform steps: http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "X_rfe = data1[data1_x_bin].columns.values[dtree_rfe.get_support()]\n",
    "rfe_results = model_selection.cross_validate(dtree, data1[X_rfe], data1[Target], cv  = cv_split)\n",
    "\n",
    "#print(dtree_rfe.grid_scores_)\n",
    "print('AFTER DT RFE Training Shape New: ', data1[X_rfe].shape) \n",
    "print('AFTER DT RFE Training Columns New: ', X_rfe)\n",
    "\n",
    "print(\"AFTER DT RFE Training w/bin score mean: {:.2f}\". format(rfe_results['train_score'].mean()*100)) \n",
    "print(\"AFTER DT RFE Test w/bin score mean: {:.2f}\". format(rfe_results['test_score'].mean()*100))\n",
    "print(\"AFTER DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(rfe_results['test_score'].std()*100*3))\n",
    "print('-'*10)\n",
    "\n",
    "\n",
    "#tune rfe model\n",
    "rfe_tune_model = model_selection.GridSearchCV(tree.DecisionTreeClassifier(), param_grid=param_grid, scoring = 'roc_auc', cv = cv_split)\n",
    "rfe_tune_model.fit(data1[X_rfe], data1[Target])\n",
    "\n",
    "#print(rfe_tune_model.cv_results_.keys())\n",
    "#print(rfe_tune_model.cv_results_['params'])\n",
    "print('AFTER DT RFE Tuned Parameters: ', rfe_tune_model.best_params_)\n",
    "#print(rfe_tune_model.cv_results_['mean_train_score'])\n",
    "print(\"AFTER DT RFE Tuned Training w/bin score mean: {:.2f}\". format(rfe_tune_model.cv_results_['mean_train_score'][tune_model.best_index_]*100)) \n",
    "#print(rfe_tune_model.cv_results_['mean_test_score'])\n",
    "print(\"AFTER DT RFE Tuned Test w/bin score mean: {:.2f}\". format(rfe_tune_model.cv_results_['mean_test_score'][tune_model.best_index_]*100))\n",
    "print(\"AFTER DT RFE Tuned Test w/bin score 3*std: +/- {:.2f}\". format(rfe_tune_model.cv_results_['std_test_score'][tune_model.best_index_]*100*3))\n",
    "print('-'*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"color: #e74c3c; text-align: center\">STOP</p>\n",
    "\n",
    "<p style=\"color: #e74c3c; text-align: center\">*Take some time to understand the code and the output above (**the scores are important**). You don't have to understand every line of code, but make sure you get what it's trying to accomplish*</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr />\n",
    "\n",
    "**Note:** If the following code gives you an error, you may have to install graphviz. This step is not overly important, just good to see and understand what you new graph looks like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Graph MLA version of Decision Tree: http://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html\n",
    "import graphviz \n",
    "dot_data = tree.export_graphviz(dtree, out_file=None, \n",
    "                                feature_names = data1_x_bin, class_names = True,\n",
    "                                filled = True, rounded = True)\n",
    "graph = graphviz.Source(dot_data) \n",
    "graph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
